{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSR: Automatic Stuttered Speech Recoginition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install tensorflow\n",
    "# !conda activate tensorflow\n",
    "# !pip install --upgrade librosa\n",
    "# !conda install progressbar2\n",
    "# !conda install matplotlib\n",
    "# !conda install colorlog\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "#%matplotlib inline\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import shutil\n",
    "import datetime\n",
    "import logging\n",
    "import colorlog\n",
    "import progressbar\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setting up progressbar and logger\n",
    "# progressbar.streams.wrap_stderr()\n",
    "logger = colorlog.getLogger(\"ASSR\")\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(colorlog.ColoredFormatter('%(log_color)s%(levelname)-8s| %(message)s'))\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction:\n",
    "    def __init__(self, n_mels=128):\n",
    "        self.n_mels = n_mels\n",
    "        self.y = None\n",
    "        self.sr = None\n",
    "        self.S = None\n",
    "        self.log_S = None\n",
    "        self.mfcc = None\n",
    "        self.delta_mfcc = None\n",
    "        self.delta2_mfcc = None\n",
    "        self.M = None\n",
    "        self.rms = None\n",
    "    \n",
    "    def loadFile(self, filename):\n",
    "        self.y, self.sr = librosa.load(filename)\n",
    "        logger.debug('File loaded: %s', filename)\n",
    "    \n",
    "    def load_y_sr(self, y, sr):\n",
    "        self.y = y\n",
    "        self.sr = sr\n",
    "    \n",
    "    def melspectrogram(self):\n",
    "        self.S = librosa.feature.melspectrogram(self.y, sr=self.sr, n_mels=self.n_mels)\n",
    "        self.log_S = librosa.amplitude_to_db(self.S, ref=np.max)\n",
    "    \n",
    "    def plotmelspectrogram(self):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        librosa.display.specshow(self.log_S, sr=self.sr, x_axis='time', y_axis='mel')\n",
    "        plt.title('mel Power Spectrogram')\n",
    "        plt.colorbar(format='%+02.0f dB')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    def extractmfcc(self, n_mfcc=13):\n",
    "        self.mfcc = librosa.feature.mfcc(S=self.log_S, n_mfcc=n_mfcc)\n",
    "#         self.delta_mfcc = librosa.feature.delta(self.mfcc)\n",
    "# HERE IT IS\n",
    "        self.delta_mfcc = librosa.feature.delta(self.mfcc,mode='nearest')\n",
    "        self.delta2_mfcc = librosa.feature.delta(self.mfcc, order=2,mode='nearest')\n",
    "        self.M = np.vstack([self.mfcc, self.delta_mfcc, self.delta2_mfcc])\n",
    "    \n",
    "    def plotmfcc(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(3, 1, 1)\n",
    "        librosa.display.specshow(self.mfcc)\n",
    "        plt.ylabel('MFCC')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(3, 1, 2)\n",
    "        librosa.display.specshow(self.delta_mfcc)\n",
    "        plt.ylabel('MFCC-$\\Delta$')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(3, 1, 3)\n",
    "        librosa.display.specshow(self.delta2_mfcc, sr=self.sr, x_axis='time')\n",
    "        plt.ylabel('MFCC-$\\Delta^2$')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    def extractrms(self):\n",
    "        self.rms = librosa.feature.rms(y=self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, datasetDir, datasetLabelFilename, datasetArrayFilename):\n",
    "        self.n_features = 80\n",
    "        logger.info(\"Number of features: %s\", self.n_features)\n",
    "#         makes 2 numpy arrays for the X (stuttering audio) and Y (NORMAL or STUTTERING classification)\n",
    "        self.X = np.empty(shape=(0, self.n_features))\n",
    "        self.Y = np.empty(shape=(0, 2))\n",
    "        \n",
    "        self.datasetArrayFilename = datasetArrayFilename\n",
    "        logger.debug(\"Dataset array filename: %s\", self.datasetArrayFilename)\n",
    "        \n",
    "#         read stuttering audio data\n",
    "        if os.path.isfile(self.datasetArrayFilename):    \n",
    "            self.__readFromFile()\n",
    "        else:\n",
    "            self.datasetDir = datasetDir\n",
    "            logger.debug(\"Dataset Directory: %s\", self.datasetDir)\n",
    "\n",
    "            self.datasetLabelFilename = datasetLabelFilename\n",
    "            logger.debug(\"Dataset labels filename: %s\", self.datasetLabelFilename)\n",
    "\n",
    "            if not os.path.isdir(self.datasetDir) or not os.path.isfile(self.datasetLabelFilename):\n",
    "                logger.info(\"%s or %s does not exists\", self.datasetDir, self.datasetLabelFilename)\n",
    "                self.__buildDatasetAndLabels('wav/release1')\n",
    "                \n",
    "            self.__build()\n",
    "            self.__writeToFile()\n",
    "    \n",
    "    def __build(self):\n",
    "        logger.info(\"Building dataset from directory: %s\", self.datasetDir)\n",
    "        num_lines = sum(1 for line in open(self.datasetLabelFilename, 'r'))\n",
    "        with open(self.datasetLabelFilename, 'r') as datasetLabelFile:\n",
    "            filesProcessed=0\n",
    "            pbar = progressbar.ProgressBar(redirect_stdout=True)\n",
    "            for line in pbar(datasetLabelFile, max_value=num_lines):\n",
    "                lineSplit = line.strip().split(' ')\n",
    "                audiofilename = lineSplit[0]\n",
    "                label = lineSplit[1]\n",
    "                try:\n",
    "                    features = FeatureExtraction()\n",
    "                    features.loadFile(os.path.join(self.datasetDir, audiofilename))\n",
    "                    features.melspectrogram()\n",
    "                    features.extractmfcc()\n",
    "# HERE IT IS\n",
    "#                     features.extractmfcc(mode='nearest')\n",
    "                    features.extractrms()\n",
    "                except ValueError:\n",
    "                    logger.warning(\"Error in extracting features from file %s\", audiofilename)\n",
    "                    continue\n",
    "                \n",
    "                featureVector = []\n",
    "                for feature in features.mfcc:\n",
    "                    featureVector.append(np.mean(feature))\n",
    "                    featureVector.append(np.var(feature))\n",
    "                \n",
    "                for feature in features.delta_mfcc:\n",
    "                    featureVector.append(np.mean(feature))\n",
    "                    featureVector.append(np.var(feature))\n",
    "                \n",
    "                for feature in features.delta2_mfcc:\n",
    "                    featureVector.append(np.mean(feature))\n",
    "                    featureVector.append(np.var(feature))\n",
    "                \n",
    "                featureVector.append(np.mean(features.rms))\n",
    "                featureVector.append(np.var(features.rms))\n",
    "                \n",
    "                self.X = np.vstack((self.X, [featureVector]))\n",
    "                \n",
    "                if label == \"STUTTER\":\n",
    "                    self.Y = np.vstack((self.Y, [0, 1]))\n",
    "                elif label == \"NORMAL\":\n",
    "                    self.Y = np.vstack((self.Y, [1, 0]))\n",
    "                else:\n",
    "                    logger.error(\"Unexpected label: %s\", label)\n",
    "                    sys.exit()\n",
    "                \n",
    "                filesProcessed += 1            \n",
    "            \n",
    "            logger.info(\"Total files processed: %d\", filesProcessed)\n",
    "    \n",
    "    def __buildDatasetAndLabels(self, audioAndChaFilesDirectory):\n",
    "        logger.info(\"Rebuilding the dataset directory and labels\")\n",
    "        if os.path.isdir(self.datasetDir):\n",
    "            shutil.rmtree(self.datasetDir)\n",
    "        os.makedirs(self.datasetDir)\n",
    "        \n",
    "        labelFile = open(self.datasetLabelFilename, 'w')\n",
    "        \n",
    "        splitDuration = 300 # milliseconds\n",
    "        pbar = progressbar.ProgressBar(redirect_stdout=True)\n",
    "        for chaFileName in pbar(os.listdir(audioAndChaFilesDirectory)):\n",
    "            if chaFileName.endswith(\".cha\"):\n",
    "                subject = chaFileName.split('.')[0]\n",
    "                wavFileName = subject + \".wav\"\n",
    "                y, sr = librosa.load(os.path.join(audioAndChaFilesDirectory, wavFileName))\n",
    "\n",
    "                logger.debug(\"Parsing file: %s\", chaFileName)\n",
    "\n",
    "                with open(os.path.join(audioAndChaFilesDirectory, chaFileName), 'r') as chaFile:\n",
    "                    sndFound = False\n",
    "                    phoFound = False\n",
    "                    startTime = -1\n",
    "                    endTime = -1\n",
    "                    label = None\n",
    "                    for line in chaFile:\n",
    "                        if not sndFound:\n",
    "                            if re.search(r\"%snd:\", line):\n",
    "                                lineSplit = line.split(\"_\")\n",
    "                                startTime = int(lineSplit[-2])\n",
    "                                endTime = lineSplit[-1]\n",
    "                                endTime = int(re.sub(r\"\\u0015\\n\", '', endTime))\n",
    "                                sndFound = True\n",
    "                        else:\n",
    "                            if re.search(r\"%pho:\", line):\n",
    "                                if re.search(r'[A-Z]', line):\n",
    "                                    label = \"STUTTER\"\n",
    "                                else:\n",
    "                                    label = \"NORMAL\"\n",
    "                                phoFound = True\n",
    "                        if sndFound and phoFound:\n",
    "                            n_splits = int(np.round((endTime - startTime) / splitDuration))\n",
    "                            \n",
    "                            startingSample = int(startTime * sr / 1000)\n",
    "                            for i in range(1, n_splits):\n",
    "                                endingSample = int(startingSample + (splitDuration * sr / 1000))\n",
    "                                audiofilename = subject + \":\" + str(startTime) + \":\" + str(int(startTime) + splitDuration) + \".wav\"\n",
    "                                labelFile.write(audiofilename + \" \" + label + \"\\n\")\n",
    "                                audio = y[startingSample:endingSample]\n",
    "                                librosa.output.write_wav(os.path.join(self.datasetDir, audiofilename), audio, sr)\n",
    "                                \n",
    "                                startingSample = endingSample\n",
    "                                startTime = int(startTime) + splitDuration\n",
    "                            \n",
    "                            endingSample = int(endTime * sr / 1000)\n",
    "                            audiofilename = subject + \":\" + str(startTime) + \":\" + str(endTime) + \".wav\"\n",
    "                            labelFile.write(audiofilename + \" \" + label + \"\\n\")\n",
    "                            audio = y[startingSample:endingSample]\n",
    "                            librosa.output.write_wav(os.path.join(self.datasetDir, audiofilename), audio, sr)\n",
    "                            \n",
    "                            \n",
    "                            sndFound = False\n",
    "                            phoFound = False\n",
    "                            startTime = -1\n",
    "                            endTime = -1\n",
    "                            label = None\n",
    "\n",
    "        labelFile.close()\n",
    "    \n",
    "    def __writeToFile(self, filename=None):\n",
    "        if filename == None:\n",
    "            filename = self.datasetArrayFilename\n",
    "            \n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "        np.savetxt(filename, np.hstack((self.X, self.Y)))\n",
    "        logger.info(\"Array stored in file %s\", filename)\n",
    "    \n",
    "    def __readFromFile(self, filename=None):\n",
    "        if filename == None:\n",
    "            filename = self.datasetArrayFilename\n",
    "            \n",
    "        if not os.path.isfile(filename):\n",
    "            logger.error(\"%s does not exists or is not a file\", filename)\n",
    "            sys.exit()\n",
    "        matrix = np.loadtxt(filename)\n",
    "        self.X = matrix[:, 0:self.n_features]\n",
    "        self.Y = matrix[:, self.n_features:]\n",
    "#         I just added this\n",
    "        self.Y.astype(float)\n",
    "        print('self.y',self.Y, type(self.Y))\n",
    "        print('self.x',self.X)\n",
    "        logger.info(\"Array read from file %s\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, X_train=None, Y_train=None, X_test=None, Y_test=None):\n",
    "        # Data\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        \n",
    "        # Learning Parameters\n",
    "        self.learning_rate = 0.001\n",
    "#         minimzes in increments 1200 times\n",
    "        self.training_epochs = 1200\n",
    "#         adds 100 audio samples at a time\n",
    "        self.batch_size = 100\n",
    "        self.display_step = 100\n",
    "\n",
    "        # Model Parameters\n",
    "        self.n_hidden = [10, 10, 10]\n",
    "        self.hiddenLayers = len(self.n_hidden)\n",
    "        self.n_input = 80\n",
    "        self.n_classes = 2\n",
    "\n",
    "        logger.debug(\"Neural network of depth %d\", self.hiddenLayers)\n",
    "        for i in range(self.hiddenLayers):\n",
    "            logger.debug(\"Depth of layer %d is %d\", (i + 1), self.n_hidden[i])\n",
    "\n",
    "        self.x = tf.placeholder(\"float\", [None, self.n_input])\n",
    "        self.y = tf.placeholder(\"float\", [None, self.n_classes])\n",
    "        self.layer = None\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "        # Model\n",
    "        self.model = self.__network(self.x)\n",
    "        self.save_path = None\n",
    "\n",
    "        # Loss function and optimizer IMPORTANT\n",
    "#         self.cost = tf.reduce_mean(tf.nn.mean_squared_error(weights=None, labels=self.y,))\n",
    "        \n",
    "#         original: apparently softmax rounds to an integer\n",
    "#         self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.model, labels=self.y))\n",
    "    \n",
    "#     new loss function: softmax means it rounds to 0 or 1, sigmoid means it doesn't\n",
    "        self.cost = tf.reduce_mean(tf.compat.v1.nn.sigmoid_cross_entropy_with_logits(logits=self.model, labels=self.y))\n",
    "    \n",
    "\n",
    "\n",
    "#         uses adam optimizer from cornell\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\n",
    "        # Initialize the variables\n",
    "        self.init = tf.global_variables_initializer()\n",
    "    \n",
    "    def setTrainData(self, X, Y):\n",
    "        self.X_train = X\n",
    "        self.Y_train = Y\n",
    "        \n",
    "    def setTestData(self, X, Y):\n",
    "        self.X_test = X\n",
    "        self.Y_test = Y\n",
    "        \n",
    "    def __network(self, x):\n",
    "        self.layer = []\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        for n_layer in range(self.hiddenLayers):\n",
    "            if n_layer == 0:\n",
    "                self.weights.append(tf.Variable(tf.random_normal([self.n_input, self.n_hidden[n_layer]])))\n",
    "                self.biases.append(tf.Variable(tf.random_normal([self.n_hidden[n_layer]])))\n",
    "#                 i think that tf.nn.relu is the function that rounds the output layer to 0 or 1\n",
    "                self.layer.append(tf.nn.relu(tf.add(tf.matmul(x, self.weights[n_layer]), self.biases[n_layer])))\n",
    "            else:\n",
    "                self.weights.append(tf.Variable(tf.random_normal([self.n_hidden[n_layer - 1], self.n_hidden[n_layer]])))\n",
    "                self.biases.append(tf.Variable(tf.random_normal([self.n_hidden[n_layer]])))\n",
    "                self.layer.append(tf.nn.relu(tf.add(tf.matmul(self.layer[n_layer - 1], self.weights[n_layer]), self.biases[n_layer])))\n",
    "\n",
    "\n",
    "        # Output layer\n",
    "        self.weights.append(tf.Variable(tf.random_normal([self.n_hidden[self.hiddenLayers - 1], self.n_classes])))\n",
    "        self.biases.append(tf.Variable(tf.random_normal([self.n_classes])))\n",
    "        self.layer.append(tf.matmul(self.layer[self.hiddenLayers - 1], self.weights[self.hiddenLayers]) + self.biases[self.hiddenLayers])\n",
    "        print('self.layer',self.layer, self.layer[self.hiddenLayers],self.hiddenLayers)\n",
    "        return self.layer[self.hiddenLayers]\n",
    "    \n",
    "    def train(self):\n",
    "        logger.info(\"Training the neural network\")\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(self.init)\n",
    "            pbarWidgets = [\n",
    "                progressbar.Percentage(),\n",
    "                ' (',\n",
    "                progressbar.SimpleProgress(),\n",
    "                ') ',\n",
    "                progressbar.Bar(),\n",
    "                ' ',\n",
    "                progressbar.Timer(),\n",
    "                ' ',\n",
    "                progressbar.ETA(),\n",
    "                ' ',\n",
    "                progressbar.DynamicMessage('Cost'),\n",
    "            ]\n",
    "            with progressbar.ProgressBar(max_value=self.training_epochs, redirect_stdout=True, widgets=pbarWidgets) as pbar:\n",
    "                for epoch in range(self.training_epochs):\n",
    "                    avg_cost = 0\n",
    "                    total_batch = int(len(self.X_train) / self.batch_size)\n",
    "                    X_batches = np.array_split(self.X_train, total_batch)\n",
    "                    Y_batches = np.array_split(self.Y_train, total_batch)\n",
    "\n",
    "                    for i in range(total_batch):\n",
    "                        batch_x, batch_y = X_batches[i], Y_batches[i]\n",
    "                        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "#                         gets cost value\n",
    "                        _, c = sess.run([self.optimizer, self.cost], feed_dict={self.x: batch_x, self.y: batch_y})\n",
    "\n",
    "                        # Compute average loss\n",
    "                        avg_cost += c / total_batch\n",
    "\n",
    "                    pbar.update(epoch + 1, Cost=avg_cost)\n",
    "                \n",
    "            logger.info(\"Optimization Finished!\")\n",
    "\n",
    "            evalAccuracy = self.__getAccuracy()\n",
    "            \n",
    "            global result \n",
    "            result = tf.argmax(self.model, 1).eval({self.x: self.X_test, self.y: self.Y_test})\n",
    "            \n",
    "            tfSessionsDir = \"tfSessions\"\n",
    "            if not os.path.isdir(tfSessionsDir):\n",
    "                os.makedirs(tfSessionsDir)\n",
    "            timestamp = '{:%Y-%m-%d-%H:%M:%S}'.format(datetime.datetime.now()) + '-' + str(evalAccuracy)\n",
    "            os.makedirs(os.path.join(tfSessionsDir, timestamp))\n",
    "            modelfilename =  os.path.join(os.path.join(tfSessionsDir, timestamp), 'session.ckpt')\n",
    "            self.save_path = saver.save(sess, modelfilename)\n",
    "            \n",
    "            with open(os.path.join(os.path.join(tfSessionsDir, timestamp), 'details.txt'), 'w') as details:\n",
    "                details.write(\"learning_rate = \" + str(self.learning_rate) + \"\\n\")\n",
    "                details.write(\"training_epochs = \" + str(self.training_epochs) + \"\\n\")\n",
    "                details.write(\"batch_size = \" + str(self.batch_size) + \"\\n\")\n",
    "                details.write(\"display_step = \" + str(self.display_step) + \"\\n\")\n",
    "                details.write(\"n_hidden = \" + str(self.n_hidden) + \"\\n\")\n",
    "                details.write(\"hiddenLayers = \" + str(self.hiddenLayers) + \"\\n\")\n",
    "                details.write(\"n_input = \" + str(self.n_input) + \"\\n\")\n",
    "                details.write(\"n_classes = \" + str(self.n_classes) + \"\\n\")\n",
    "                \n",
    "            logger.info(\"Model saved in file: %s\" % self.save_path)\n",
    "    \n",
    "    def getModelPath(self):\n",
    "        return self.save_path\n",
    "        \n",
    "    def __getAccuracy(self):\n",
    "        # Test model\n",
    "        correct_prediction = tf.equal(tf.argmax(self.model, 1), tf.argmax(self.y, 1))\n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        evalAccuracy = accuracy.eval({self.x: self.X_test, self.y: self.Y_test})\n",
    "        logger.info(\"Accuracy: %f\", evalAccuracy)\n",
    "        return evalAccuracy\n",
    "        \n",
    "    def loadAndClassify(self, filename, X):            \n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, filename)\n",
    "#             very IMPORTANT\n",
    "# bookmark\n",
    "# original\n",
    "#             prediction_model = tf.argmax(self.model, 1)\n",
    "        \n",
    "            print('tf.argmax(self.model, 1)',tf.argmax(self.model, 1))\n",
    "#     changed\n",
    "            prediction_model = tf.cast(self.model, dtype=tf.float32)\n",
    "            print('tf.cast(self.model, dtype=tf.float32)',tf.cast(self.model, dtype=tf.float32))\n",
    "    \n",
    "        \n",
    "#             rint('prediction_model',prediction_model)\n",
    "            print('prediction_model.eval({self.x: X})',prediction_model.eval({self.x: X}))\n",
    "#             rint('saver',saver)\n",
    "            return prediction_model.eval({self.x: X})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using the NN model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioCorrection():\n",
    "    def __init__(self, audiofile, tfSessionFile, segmentLength=300, segmentHop=100, n_features=80, correctionsDir='corrections'):\n",
    "        self.tfSessionFile = tfSessionFile\n",
    "        self.segmentLength = segmentLength\n",
    "        self.segmentHop = segmentHop\n",
    "        self.n_features = n_features\n",
    "        self.correctionsDir = correctionsDir\n",
    "        self.samplesPerSegment = None\n",
    "        self.samplesToSkipPerHop = None\n",
    "        self.upperLimit = None\n",
    "        self.inputFilename = None\n",
    "        self.y = None\n",
    "        self.sr = None\n",
    "        self.target_sr = 16000\n",
    "        NORMAL = 0\n",
    "        STUTTER = 1\n",
    "        self.speech = {NORMAL: [], STUTTER: []}\n",
    "        self.smoothingSamples = 1000\n",
    "        self.__loadfile(audiofile)\n",
    "    \n",
    "    def __loadfile(self, inputFilename):\n",
    "        if not os.path.isfile(inputFilename):\n",
    "            logger.error(\"%s does not exists or is not a file\", inputFilename)\n",
    "            sys.exit()\n",
    "        self.inputFilename = inputFilename\n",
    "        logger.info(\"Loading file %s\", self.inputFilename)\n",
    "        self.y, self.sr = librosa.load(self.inputFilename)\n",
    "        self.samplesPerSegment = int(self.segmentLength * self.sr / 1000)\n",
    "        self.samplesToSkipPerHop = int(self.segmentHop * self.sr / 1000)\n",
    "        self.upperLimit = len(self.y) - self.samplesPerSegment\n",
    "\n",
    "#         IMPORTANT\n",
    "    def process(self):\n",
    "        logger.info(\"Attempting to correct %s\", self.inputFilename)\n",
    "        X = np.empty(shape=(0, self.n_features))\n",
    "        durations = np.empty(shape=(0, 2))\n",
    "\n",
    "        pbar = progressbar.ProgressBar()\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for start in pbar(range(0, self.upperLimit, self.samplesToSkipPerHop)):\n",
    "            end = start + self.samplesPerSegment\n",
    "            audio = self.y[start:end]\n",
    "\n",
    "            featureVector = self.__getFeatureVector(audio, self.sr)\n",
    "            if featureVector != None:\n",
    "                X = np.vstack((X, [featureVector]))\n",
    "                durations = np.vstack((durations, [start, end]))\n",
    "        \n",
    "        audio = self.y[end:]\n",
    "        featureVector = self.__getFeatureVector(audio, self.sr)\n",
    "        if featureVector != None:\n",
    "            X = np.vstack((X, [featureVector]))\n",
    "            durations = np.vstack((durations, [end, self.upperLimit + self.samplesPerSegment]))\n",
    "        logger.debug(\"Finished extracting features\")\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        nn = NeuralNetwork()\n",
    "#         IMPORTANT this is where audio samples get classified as stuttering or not stuttering\n",
    "# originally this accepted a list of 1's or 0's, now it's going to accept floats (hopefully)\n",
    "        \n",
    "        old_classificationResult = nn.loadAndClassify(self.tfSessionFile, X)\n",
    "        \n",
    "#     BOOKMARK\n",
    "    \n",
    "        temporary_list = []\n",
    "        print('old_classificationResult',old_classificationResult)\n",
    "        for n,s in old_classificationResult:\n",
    "            index = (1/math.pi) * math.atan(s-n) + .5\n",
    "            temporary_list.append(index)\n",
    "        \n",
    "        classificationResult = np.array(temporary_list)\n",
    "    \n",
    "    \n",
    "        print('new classificationResult',classificationResult)\n",
    "        for i in classificationResult[:20]:\n",
    "            print(i)\n",
    "        \n",
    "        logger.debug(\"Finished classification of segments\")\n",
    "        \n",
    "        set_trace()\n",
    "        currentSegment = {'type': classificationResult[0], 'start': durations[0][0], 'end': durations[0][1]}\n",
    "        for (label, [start, end]) in zip(classificationResult[1:], durations[1:]):\n",
    "            if currentSegment['type'] == label:\n",
    "                currentSegment['end'] = end\n",
    "            else:\n",
    "                self.speech[currentSegment['type']].append((currentSegment['start'], currentSegment['end']))\n",
    "                currentSegment['type'] = label\n",
    "                currentSegment['start'] = start\n",
    "                currentSegment['end'] = end\n",
    "    \n",
    "    def __getFeatureVector(self, y, sr):\n",
    "        try:\n",
    "            features = FeatureExtraction()\n",
    "            features.load_y_sr(y, sr)\n",
    "            features.melspectrogram()\n",
    "            features.extractmfcc()\n",
    "            features.extractrms()\n",
    "        except ValueError:\n",
    "            logger.warning(\"Error extracting features\")\n",
    "            return None\n",
    "\n",
    "        featureVector = []\n",
    "        for feature in features.mfcc:\n",
    "            featureVector.append(np.mean(feature))\n",
    "            featureVector.append(np.var(feature))\n",
    "\n",
    "        for feature in features.delta_mfcc:\n",
    "            featureVector.append(np.mean(feature))\n",
    "            featureVector.append(np.var(feature))\n",
    "\n",
    "        for feature in features.delta2_mfcc:\n",
    "            featureVector.append(np.mean(feature))\n",
    "            featureVector.append(np.var(feature))\n",
    "\n",
    "        featureVector.append(np.mean(features.rms))\n",
    "        featureVector.append(np.var(features.rms))\n",
    "        \n",
    "        return featureVector\n",
    "    \n",
    "    def saveCorrectedAudio(self):\n",
    "        NORMAL = 0\n",
    "        STUTTER = 1\n",
    "        if not os.path.isdir(self.correctionsDir):\n",
    "            os.makedirs(self.correctionsDir)\n",
    "        outputFilenamePrefix = os.path.join(self.correctionsDir, os.path.splitext(os.path.basename(self.inputFilename))[0])\n",
    "        \n",
    "        normalSpeech = np.ndarray(shape=(1, 0))\n",
    "        (start, end) = self.speech[NORMAL][0]\n",
    "        normalSpeech = np.append(normalSpeech, self.y[int(start):int(end)])\n",
    "        for (start, end) in self.speech[NORMAL][1:]:\n",
    "            # Smoothing\n",
    "            previousSample = normalSpeech[-1]\n",
    "            nextSample = self.y[int(start)]\n",
    "            if nextSample > previousSample:\n",
    "                low, high = previousSample, nextSample\n",
    "            else:\n",
    "                low, high = nextSample, previousSample\n",
    "            \n",
    "            step = (high - low) / self.smoothingSamples\n",
    "            \n",
    "            normalSpeech = np.append(normalSpeech, np.arange(low, high, step))\n",
    "            normalSpeech = np.append(normalSpeech, self.y[int(start):int(end)])\n",
    "\n",
    "        stutteredSpeech = np.ndarray(shape=(1, 0))\n",
    "        for (start, end) in self.speech[STUTTER]:\n",
    "            stutteredSpeech = np.append(stutteredSpeech, self.y[int(start):int(end)])\n",
    "\n",
    "        # Resampling the audio\n",
    "        logger.debug(\"Resampling corrected audio from %d to %d\", self.sr, self.target_sr)\n",
    "        resampledNormalSpeech = librosa.resample(normalSpeech, self.sr, self.target_sr)\n",
    "        resampledStutteredSpeech = librosa.resample(stutteredSpeech, self.sr, self.target_sr)\n",
    "        librosa.output.write_wav(outputFilenamePrefix + \"-corrected.wav\", normalSpeech, self.sr)\n",
    "        librosa.output.write_wav(outputFilenamePrefix + \"-stuttered.wav\", stutteredSpeech, self.sr)\n",
    "        logger.info(\"Corrected audio saved as %s\", outputFilenamePrefix + \"-corrected.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train=False, correct=False):\n",
    "    if train:\n",
    "#         imports data files from the working directory\n",
    "        dataset = Dataset('dataset', 'datasetLabels.txt', 'datasetArray80.gz')\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(dataset.X, dataset.Y)\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        nn = NeuralNetwork(X_train, Y_train, X_test, Y_test)\n",
    "        nn.train()\n",
    "\n",
    "    if correct:\n",
    "        audiofile = 'stuttering_sample.wav'\n",
    "        \n",
    "#         this doesn't get updated automatically so change the rf session path to the one you just modified manually\n",
    "        if train:\n",
    "            tfSessionFile = nn.getModelPath()\n",
    "#             rint(\"Here, fucko\",nn.getModelPath)\n",
    "        else:\n",
    "            tfSessionFile = 'tfSessions/2019-09-17-15:15:09-0.8508892/session.ckpt'\n",
    "        print('tfSessionFile',tfSessionFile)\n",
    "        correction = AudioCorrection(audiofile, tfSessionFile)\n",
    "        correction.process()\n",
    "        correction.saveCorrectedAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    | Loading file stuttering_sample.wav\u001b[0m\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0917 17:50:36.773874 4570781120 <ipython-input-7-826a4322a461>:26] Loading file stuttering_sample.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfSessionFile tfSessions/2019-09-17-15:15:09-0.8508892/session.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    | Attempting to correct stuttering_sample.wav\u001b[0m\n",
      "I0917 17:50:38.348001 4570781120 <ipython-input-7-826a4322a461>:34] Attempting to correct stuttering_sample.wav\n",
      "100% (71 of 71) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "W0917 17:50:39.671394 4570781120 deprecation.py:323] From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.layer [<tf.Tensor 'Relu:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'Relu_1:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'Relu_2:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'add_3:0' shape=(?, 2) dtype=float32>] Tensor(\"add_3:0\", shape=(?, 2), dtype=float32) 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0917 17:50:40.592906 4570781120 deprecation.py:323] From /anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(self.model, 1) Tensor(\"ArgMax:0\", shape=(?,), dtype=int64)\n",
      "tf.cast(self.model, dtype=tf.float32) Tensor(\"add_3:0\", shape=(?, 2), dtype=float32)\n",
      "prediction_model.eval({self.x: X}) [[ 1.19177351e+01  2.13425217e+01]\n",
      " [ 1.57783079e+00  1.12775812e+01]\n",
      " [ 3.27610350e+00  8.11644840e+00]\n",
      " [-6.63837969e-01  9.17687321e+00]\n",
      " [-2.78209472e+00  1.26068048e+01]\n",
      " [-7.40110064e+00  1.56875544e+01]\n",
      " [-3.42762530e-01  1.33891535e+01]\n",
      " [ 3.06010664e-01  7.48839617e+00]\n",
      " [-2.74957705e+00  8.84557438e+00]\n",
      " [ 2.73543882e+00  2.81731248e-01]\n",
      " [ 1.94527006e+00  1.94591582e+00]\n",
      " [-2.81508684e+00  1.25344782e+01]\n",
      " [-2.67183602e-01  3.67015886e+00]\n",
      " [ 2.63923407e-03  2.81890154e+00]\n",
      " [-3.98277712e+00  1.40591059e+01]\n",
      " [ 2.00507689e+00  5.52709246e+00]\n",
      " [ 1.21754789e+00  5.81127214e+00]\n",
      " [ 5.15031004e+00  1.08068781e+01]\n",
      " [ 1.77150383e+01  1.85554123e+01]\n",
      " [ 1.87733269e+01  3.68864670e+01]\n",
      " [ 1.19861555e+01  9.42619920e-01]\n",
      " [ 4.46293449e+01 -5.58586502e+01]\n",
      " [-4.82949715e+01  3.80763428e+02]\n",
      " [-1.30864153e+01  1.12026115e+02]\n",
      " [ 8.33423901e+00  3.15212326e+01]\n",
      " [-4.09351885e-01  4.43073654e+01]\n",
      " [ 2.12234001e+01  1.04694757e+01]\n",
      " [-2.32135439e+00  1.40242853e+01]\n",
      " [ 7.33463621e+00 -3.29087019e+00]\n",
      " [ 5.87754393e+00 -7.81379104e-01]\n",
      " [ 6.30603552e+00 -7.13080764e-01]\n",
      " [ 3.56184196e+01 -4.99416580e+01]\n",
      " [ 1.24282331e+01  1.55993586e+01]\n",
      " [-4.00924349e+00  3.35309372e+01]\n",
      " [-5.98688555e+00  3.83848801e+01]\n",
      " [-3.59322023e+00  1.83650131e+01]\n",
      " [-4.42481661e+00  1.84544601e+01]\n",
      " [-3.57963896e+00  1.61686935e+01]\n",
      " [-3.00168276e+00  7.57248735e+00]\n",
      " [ 4.73327208e+00  6.53734636e+00]\n",
      " [ 7.35922956e+00 -2.25122786e+00]\n",
      " [ 2.93192053e+00 -2.98220291e+01]\n",
      " [ 2.18165922e+00  1.88402617e+00]\n",
      " [ 2.24498653e+00  7.23839617e+00]\n",
      " [ 7.45636320e+00 -1.70703828e+00]\n",
      " [ 5.27061033e+00  1.79601974e+01]\n",
      " [ 3.77266960e+01 -2.20627518e+01]\n",
      " [ 1.42301435e+01 -1.44685125e+01]\n",
      " [ 1.21441603e+01 -1.67602615e+01]\n",
      " [ 1.86337090e+01 -3.96071854e+01]\n",
      " [ 6.30669737e+00 -1.19764471e+01]\n",
      " [-3.54041634e+01  1.43875977e+02]\n",
      " [ 3.56449461e+00  4.60429611e+01]\n",
      " [ 6.09757566e+00  2.00651779e+01]\n",
      " [-4.80085754e+01  2.94153564e+02]\n",
      " [-2.30459480e+01  8.29792404e+01]\n",
      " [-3.43004341e+01  1.16937248e+02]\n",
      " [-4.48307228e+01  2.20428467e+02]\n",
      " [-1.84121437e+01  4.67346115e+01]\n",
      " [-3.65591927e+01  1.44939697e+02]\n",
      " [-2.21842384e+01  4.25573654e+01]\n",
      " [-2.65309715e+01  1.49440430e+02]\n",
      " [-4.77613497e+00  2.51920395e+01]\n",
      " [-3.20642519e+00  1.12502069e+01]\n",
      " [ 6.52321196e+00  2.79784441e+00]\n",
      " [ 9.05384350e+00  1.65087187e+00]\n",
      " [ 1.43516111e+00  3.93187761e+00]\n",
      " [-4.47080660e+00  6.43188238e+00]\n",
      " [-5.24925661e+00  1.34065180e+01]\n",
      " [-6.28804636e+00  1.53019800e+01]\n",
      " [ 3.43108463e+00  1.77945769e+00]\n",
      " [-1.72198906e+01  7.09119797e+01]]\n",
      "old_classificationResult [[ 1.19177351e+01  2.13425217e+01]\n",
      " [ 1.57783079e+00  1.12775812e+01]\n",
      " [ 3.27610350e+00  8.11644840e+00]\n",
      " [-6.63837969e-01  9.17687321e+00]\n",
      " [-2.78209472e+00  1.26068048e+01]\n",
      " [-7.40110064e+00  1.56875544e+01]\n",
      " [-3.42762530e-01  1.33891535e+01]\n",
      " [ 3.06010664e-01  7.48839617e+00]\n",
      " [-2.74957705e+00  8.84557438e+00]\n",
      " [ 2.73543882e+00  2.81731248e-01]\n",
      " [ 1.94527006e+00  1.94591582e+00]\n",
      " [-2.81508684e+00  1.25344782e+01]\n",
      " [-2.67183602e-01  3.67015886e+00]\n",
      " [ 2.63923407e-03  2.81890154e+00]\n",
      " [-3.98277712e+00  1.40591059e+01]\n",
      " [ 2.00507689e+00  5.52709246e+00]\n",
      " [ 1.21754789e+00  5.81127214e+00]\n",
      " [ 5.15031004e+00  1.08068781e+01]\n",
      " [ 1.77150383e+01  1.85554123e+01]\n",
      " [ 1.87733269e+01  3.68864670e+01]\n",
      " [ 1.19861555e+01  9.42619920e-01]\n",
      " [ 4.46293449e+01 -5.58586502e+01]\n",
      " [-4.82949715e+01  3.80763428e+02]\n",
      " [-1.30864153e+01  1.12026115e+02]\n",
      " [ 8.33423901e+00  3.15212326e+01]\n",
      " [-4.09351885e-01  4.43073654e+01]\n",
      " [ 2.12234001e+01  1.04694757e+01]\n",
      " [-2.32135439e+00  1.40242853e+01]\n",
      " [ 7.33463621e+00 -3.29087019e+00]\n",
      " [ 5.87754393e+00 -7.81379104e-01]\n",
      " [ 6.30603552e+00 -7.13080764e-01]\n",
      " [ 3.56184196e+01 -4.99416580e+01]\n",
      " [ 1.24282331e+01  1.55993586e+01]\n",
      " [-4.00924349e+00  3.35309372e+01]\n",
      " [-5.98688555e+00  3.83848801e+01]\n",
      " [-3.59322023e+00  1.83650131e+01]\n",
      " [-4.42481661e+00  1.84544601e+01]\n",
      " [-3.57963896e+00  1.61686935e+01]\n",
      " [-3.00168276e+00  7.57248735e+00]\n",
      " [ 4.73327208e+00  6.53734636e+00]\n",
      " [ 7.35922956e+00 -2.25122786e+00]\n",
      " [ 2.93192053e+00 -2.98220291e+01]\n",
      " [ 2.18165922e+00  1.88402617e+00]\n",
      " [ 2.24498653e+00  7.23839617e+00]\n",
      " [ 7.45636320e+00 -1.70703828e+00]\n",
      " [ 5.27061033e+00  1.79601974e+01]\n",
      " [ 3.77266960e+01 -2.20627518e+01]\n",
      " [ 1.42301435e+01 -1.44685125e+01]\n",
      " [ 1.21441603e+01 -1.67602615e+01]\n",
      " [ 1.86337090e+01 -3.96071854e+01]\n",
      " [ 6.30669737e+00 -1.19764471e+01]\n",
      " [-3.54041634e+01  1.43875977e+02]\n",
      " [ 3.56449461e+00  4.60429611e+01]\n",
      " [ 6.09757566e+00  2.00651779e+01]\n",
      " [-4.80085754e+01  2.94153564e+02]\n",
      " [-2.30459480e+01  8.29792404e+01]\n",
      " [-3.43004341e+01  1.16937248e+02]\n",
      " [-4.48307228e+01  2.20428467e+02]\n",
      " [-1.84121437e+01  4.67346115e+01]\n",
      " [-3.65591927e+01  1.44939697e+02]\n",
      " [-2.21842384e+01  4.25573654e+01]\n",
      " [-2.65309715e+01  1.49440430e+02]\n",
      " [-4.77613497e+00  2.51920395e+01]\n",
      " [-3.20642519e+00  1.12502069e+01]\n",
      " [ 6.52321196e+00  2.79784441e+00]\n",
      " [ 9.05384350e+00  1.65087187e+00]\n",
      " [ 1.43516111e+00  3.93187761e+00]\n",
      " [-4.47080660e+00  6.43188238e+00]\n",
      " [-5.24925661e+00  1.34065180e+01]\n",
      " [-6.28804636e+00  1.53019800e+01]\n",
      " [ 3.43108463e+00  1.77945769e+00]\n",
      " [-1.72198906e+01  7.09119797e+01]]\n",
      "new classificationResult [0.96635219 0.96729923 0.93515055 0.96776443 0.97934466 0.98622219\n",
      " 0.97686055 0.95596495 0.97261578 0.12318434 0.50020555 0.97929188\n",
      " 0.92083011 0.89139466 0.9823752  0.9119403  0.9317721  0.94430286\n",
      " 0.72246011 0.9824444  0.02874479 0.00316754 0.99925812 0.99745587\n",
      " 0.98628055 0.99288282 0.02951454 0.98055055 0.02986917 0.04744744\n",
      " 0.04504586 0.00372014 0.90276427 0.99152283 0.99282751 0.98551386\n",
      " 0.98609626 0.98389544 0.96998667 0.83889087 0.03300244 0.0097152\n",
      " 0.40791808 0.93708626 0.03460017 0.9749674  0.00532335 0.01108697\n",
      " 0.01100811 0.00546486 0.01739269 0.99822453 0.99250794 0.97724966\n",
      " 0.99906971 0.99699788 0.99789533 0.99880001 0.99511434 0.99824623\n",
      " 0.99508377 0.99819115 0.98938234 0.97801676 0.08347608 0.04273889\n",
      " 0.87873673 0.97088592 0.98295404 0.98526715 0.17329655 0.99638841]\n",
      "0.9663521938649245\n",
      "0.9672992337219346\n",
      "0.9351505482592087\n",
      "0.9677644282274658\n",
      "0.9793446584788515\n",
      "0.9862221914864457\n",
      "0.9768605507518485\n",
      "0.9559649523679417\n",
      "0.9726157783603269\n",
      "0.12318433764547959\n",
      "0.5002055507199503\n",
      "0.9792918768038545\n",
      "0.9208301120450801\n",
      "0.8913946565319206\n",
      "0.9823752034736336\n",
      "0.9119402974156268\n",
      "0.9317721046978451\n",
      "0.9443028622467999\n",
      "0.7224601133636259\n",
      "0.9824443981854398\n",
      "> \u001b[0;32m<ipython-input-7-826a4322a461>\u001b[0m(82)\u001b[0;36mprocess\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     80 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     81 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 82 \u001b[0;31m        \u001b[0mcurrentSegment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclassificationResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     83 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificationResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     84 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mcurrentSegment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> classificationResult\n",
      "array([0.96635219, 0.96729923, 0.93515055, 0.96776443, 0.97934466,\n",
      "       0.98622219, 0.97686055, 0.95596495, 0.97261578, 0.12318434,\n",
      "       0.50020555, 0.97929188, 0.92083011, 0.89139466, 0.9823752 ,\n",
      "       0.9119403 , 0.9317721 , 0.94430286, 0.72246011, 0.9824444 ,\n",
      "       0.02874479, 0.00316754, 0.99925812, 0.99745587, 0.98628055,\n",
      "       0.99288282, 0.02951454, 0.98055055, 0.02986917, 0.04744744,\n",
      "       0.04504586, 0.00372014, 0.90276427, 0.99152283, 0.99282751,\n",
      "       0.98551386, 0.98609626, 0.98389544, 0.96998667, 0.83889087,\n",
      "       0.03300244, 0.0097152 , 0.40791808, 0.93708626, 0.03460017,\n",
      "       0.9749674 , 0.00532335, 0.01108697, 0.01100811, 0.00546486,\n",
      "       0.01739269, 0.99822453, 0.99250794, 0.97724966, 0.99906971,\n",
      "       0.99699788, 0.99789533, 0.99880001, 0.99511434, 0.99824623,\n",
      "       0.99508377, 0.99819115, 0.98938234, 0.97801676, 0.08347608,\n",
      "       0.04273889, 0.87873673, 0.97088592, 0.98295404, 0.98526715,\n",
      "       0.17329655, 0.99638841])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> label\n",
      "*** NameError: name 'label' is not defined\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-7-826a4322a461>\u001b[0m(83)\u001b[0;36mprocess\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     81 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     82 \u001b[0;31m        \u001b[0mcurrentSegment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclassificationResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 83 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificationResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     84 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mcurrentSegment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     85 \u001b[0;31m                \u001b[0mcurrentSegment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-7-826a4322a461>\u001b[0m(84)\u001b[0;36mprocess\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     82 \u001b[0;31m        \u001b[0mcurrentSegment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclassificationResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     83 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificationResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 84 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mcurrentSegment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     85 \u001b[0;31m                \u001b[0mcurrentSegment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     86 \u001b[0;31m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> label\n",
      "0.9672992337219346\n",
      "ipdb> classificationResult[2]\n",
      "0.9351505482592087\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c22928f44580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-64243d485fb1>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(train, correct)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tfSessionFile'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtfSessionFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mcorrection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioCorrection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudiofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfSessionFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mcorrection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mcorrection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveCorrectedAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-826a4322a461>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mcurrentSegment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclassificationResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificationResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mcurrentSegment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mcurrentSegment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-826a4322a461>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mcurrentSegment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclassificationResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificationResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mcurrentSegment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mcurrentSegment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     testing\n",
    "    run(False, True)\n",
    "    \n",
    "#     training\n",
    "#     run(False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
